This document* explores the inner workings and conceptual reasoning behind who.cares, designed to help users assess the significance of political issues in their lives. The focus here is on the logic of how weights are calculated, the role of AI in reasoning, and how user inputs shape the output, rather than technical implementation details. This explanation is aimed at a technically minded audience with an interest in politics and analysis.

*This document was generated by AI :)*

---

## 1. **Purpose and Philosophical Foundations**

At its core, who.cares seeks to answer a deeply human question: *How much should I care about this issue?* It provides a framework for prioritizing political topics based on structured, evidence-driven reasoning. The methodology relies on combining:

- **Quantifiable Importance**: Assigning weights (1-10) to aspects of the issue.
- **Qualitative Explanation**: Contextualizing those weights with facts and reasoning.
- **Personal Relevance**: Incorporating user-specific inputs to make the assessment actionable.

The driving principle is to balance objectivity (statistical and policy impact) with subjectivity (user preferences and personal relevance).

---

## 2. **How Weights Are Determined**

### The Categories
The tool evaluates each topic across predefined categories:

1. **Statistical Impact**:
   - Assesses how broadly the issue affects the population.
   - Anchored in data points like percentages, per capita statistics, or economic metrics.

2. **Policy Impact Potential**:
   - Measures the feasibility of addressing the issue through legislative or regulatory changes.
   - Considers alternative mechanisms (e.g., private sector solutions).

3. **Social Relevance**:
   - Focuses on cultural and societal dimensions, such as correcting imbalances or addressing inequities.

4. **Personal Relevance** (optional):
   - Centers on the user's subjective experience and personal stakes.
   - Excluded from broader statistical or policy considerations.

### Weight Calculation
Each category receives a weight on a 1-10 scale. These weights are designed to:

- Reflect the magnitude of the issue’s importance.
- Be intuitive while remaining nuanced enough for comparison.

The AI determines weights based on:

1. **Empirical Data**:
   - For example, statistical impact might receive a higher score if the issue affects a majority of the population or disproportionately impacts vulnerable groups.

2. **Relative Significance**:
   - Issues that are pivotal to public policy or deeply divisive in society often score higher.

3. **User-Defined Priorities**:
   - Personal inputs can amplify certain weights, such as giving more weight to "Personal Relevance" when users specify personal stakes.

---

## 3. **How AI Drives the Reasoning**

The reasoning behind the weights is powered by OpenAI’s GPT 4o model, guided by strict instructions to ensure consistency and relevance. Here’s how it works:

### Structured Framework
The AI operates within a rigidly defined structure:

- For each category, the AI produces:
  - **Weight**: A numeric score.
  - **Facts**: A curated list of five key data points, grounded in evidence.
  - **Sources**: Links to credible references supporting the facts.
  - **Reasoning**: A detailed explanation connecting the facts to the assigned weight.

- The AI’s instructions emphasize:
  - Prioritizing factual rigor (e.g., percentages, per capita numbers).
  - Balancing depth and accessibility (e.g., avoiding overly technical jargon).

### Integrating Context
The AI adapts its reasoning based on user inputs:

1. **Political Preference**:
   - Adjusts the perspective of the analysis (e.g., "left," "right," or "center") by emphasizing sources and reasoning aligned with the selected viewpoint.

2. **Year**:
   - Filters reasoning to align with the chosen time frame, ensuring historical or contemporary relevance.

3. **Personal Impact**:
   - Introduces a user-centric dimension, framing reasoning around how the issue aligns with the user’s stated experiences or concerns.

4. **Days Per Year**:
   - Influences the calculation of "total hours" to ensure time recommendations align with the user’s commitment levels.

---

### On AI Bias

> This is the only section of this document *not* written by AI.

LLMs have inherent biases. The structure described above attempts to mitigate those biases to the greatest degree possible, but it's likely biases from training will still bleed through.

Note that all the weights, as well as the ultimate time investment suggestion, are 100% generated by AI, without strict algorithmic processing. So it's possible and even likely that there will be some variance in both methodology and degree of bias even for the exact same inputs.

The solution to this is probably factoring out some or all analysis of results into a strict & consistent heuristic, or at least to prompt multiple LLMs and do a pass over results to smooth out bias (but the latter would significantly increase costs, so, not right now). In the meantime, keep that limitation in mind.

## 4. **The Role of Inputs in Shaping the Analysis**

User inputs are pivotal to tailoring the analysis. Here’s how each input affects the process:

1. **Topic**:
   - This is the foundational element, defining the scope of the analysis. The AI interprets the topic broadly or narrowly based on phrasing.

2. **Personal Impact**:
   - When provided, this input significantly alters the analysis by introducing a subjective dimension. It prompts the AI to highlight the topic’s relevance to the user’s life.

3. **Bias Preference**:
   - Adjusts the lens through which the topic is analyzed, tailoring both reasoning and source selection to the chosen perspective.

4. **Year**:
   - Ensures that the analysis focuses on data and arguments relevant to the specified time period, allowing for historical context or a contemporary focus.

5. **Days Per Year**:
   - Acts as a constraint on the "total hours" recommendation, ensuring it remains practical and achievable within the user’s stated parameters.

---

## 5. **The Total Hours Metric**

The "total hours" recommendation is one of the tool’s most actionable outputs. It reflects how much time users should dedicate to understanding or discussing the topic. The calculation:

1. Weighs the importance of each category (e.g., Statistical Impact may carry more weight than Social Relevance for some issues).
2. Normalizes the result based on the user’s "days per year" input, ensuring practicality.
3. Generates a detailed description explaining how the hours were calculated, demystifying the logic.

This metric bridges the gap between abstract importance and real-world actionability.

---

## 6. **The Importance of Sources**

Sources are integral to the tool’s credibility. The AI provides links to deep-dive materials, such as:

- Peer-reviewed articles.
- Government reports.
- Investigative journalism.

To enhance trust and transparency, the tool validates sources using Ground.News, which:

- Flags potential biases.
- Links to broader context for contentious topics.

> Note: ground.news rate limits this app (and this isn't approved by them anyway), so you may often see that bias checks fail. In that case, you'll get a pointer to search ground.news yourself with the provided query. I encourage you to follow up on those messages, or use your favorite fact checker for the sources returned by this tool.

This dual-layer approach ensures users can independently verify the AI’s reasoning.

---

## 7. **Why This Methodology Matters**

In a landscape dominated by information overload, this tool offers a structured approach to prioritization. It balances:

- **Rationality**: Grounding decisions in evidence and logic.
- **Personalization**: Adapting analysis to individual perspectives and constraints.

By demystifying complex topics and offering actionable insights, the tool empowers users to engage with political issues more meaningfully and effectively.
